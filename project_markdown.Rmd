---
title: "Evolution of language in literature throughout ages"
author: "Grzegorz Krochmal & Katarzyna Kryńska"
date: "02.02.2020"
output:
    rmdformats::readthedown:
    keywords: 
    highlight: tango
    code_folding: hide
    df_print: paged
    number_sections: true
    toc_depth: 5
    toc_float:
      collapsed: true
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)

library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
library(maps)
library(scales)
library(reshape)
library(wordcloud2)
library(gbm)

# Do usuniecia stopwords z baz
library(tm)

clean_dataset <- function(dataset){
  dataset <-  filter(dataset, !Lemma %in% stopwords(kind="en"))
  dataset <-  filter(dataset, nchar(Lemma) > 1)
  return(dataset)
}

#setwd("C:/Users/grzeg/Desktop/studia/Data Science/2 rok/semestr 1/Advanced_VisualisationR/projekt/Adv_Vis_R_Project")
'17th_data' <- data.frame(readxl::read_xlsx("17th_joined_file.xlsx")) %>% clean_dataset()
'18th_data' <- data.frame(readxl::read_xlsx("18th_joined_file.xlsx")) %>% clean_dataset()
'19th_data' <- data.frame(readxl::read_xlsx("19th_joined_file.xlsx")) %>% clean_dataset()
'20th_data' <- data.frame(readxl::read_xlsx("20th_joined_file.xlsx")) %>% clean_dataset()

authors_data <- data.frame(readxl::read_xlsx("Author_birthplace_with_geo_data.xlsx"))

basic_words <- readLines("basic_words.txt", warn = FALSE) %>% 
  strsplit(",") %>% unlist() %>% 
  strsplit(" ") %>% unlist() %>% 
  strsplit("/") %>% unlist()
basic_words <- basic_words[nchar(basic_words)>1 & !basic_words %in% stopwords(kind="en")]

centuries <- c("17th", "18th", "19th", "20th")
number_of_titles <- c(15, 15, 15, 14)

century_basic <- data.frame(centuries, number_of_titles)
century_basic <- cbind(century_basic, authors_data %>% group_by(Century) %>% tally(name = "Number of Authors") %>% select_at("Number of Authors"))
century_basic_long <- melt(century_basic, id=c("centuries"))
```

The goal of our project is to compare how English language evolved in four corresponding centuries, from 17th century to 20th century. To achieve this aim we collected books from specific centuries from Project Guttenberg. The books we collected were not necessarily written in English - some of them were written in other languages and then translated into English. We believe that even though these books were not originally written in English, their translations reflect English language at the corresponding age.

The initial idea was to get over at least a dozen of titles for each century based on the list of the most popular books for specific period - www.goodreads.com. However for 20th century we encountered the problem with the availability of titles because of copyrights. That's why books from 20th century are not the most popular ones but only these we could get.

## First look at the datasets - wordclouds

To create wordclouds, we used R library *wordcloud2*. We chose words that occur at least 100 times and plot them into a wordcloud, to give a quick glance on how language evolved throughout the ages.

### 17th century

```{r}
wordFreq <- `17th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```


### 18th century

```{r}
wordFreq <- `18th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

### 19th century

```{r}
wordFreq <- `19th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

### 20th century

```{r}
wordFreq <- `20th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

We can see that many of the popular words used in 17th century are also the most popular words in later ages - e.g. 'say', 'go', 'see', 'will'. However, there are some words in 17th century that seem outdated - like 'thou', 'shall' or 'thy'. On the other hand, we can see that some words gained popularity over time - e.g. 'like', which was one of the most popular words in 20th century, was less frequent in use before 20th century.

## Word frequencies

To confirm our conclusions, we plotted word frequencies. We can clearly see that compared to 20th century, in 17th century such words as 'thee', 'knight' and 'christ' were used more commonly - and reversely, in 20th century words 'tea', 'archer', 'mrs', 'miss' were much more common. Interestingly, most popular words in 17th century, such as 'go', 'say' and 'will' were also the most popular ones in 20th century.

Similarly, when we compare 18th and 19th century to 20th century, we can see that some words became less popular (like 'clergy', 'army', 'cristo') and some words gained popularity (e.g. 'archer', 'businessman', 'beaufort') but the most popular stayed the same ('come', 'always', 'return').

```{r}
library(scales)

`17th_data`$frequency <- `17th_data`$Number.of.occurences / sum(`17th_data`$Number.of.occurences)
`18th_data`$frequency <- `18th_data`$Number.of.occurences / sum(`18th_data`$Number.of.occurences)
`19th_data`$frequency <- `19th_data`$Number.of.occurences / sum(`19th_data`$Number.of.occurences)
`20th_data`$frequency <- `20th_data`$Number.of.occurences / sum(`20th_data`$Number.of.occurences)

frequency <- `17th_data` %>% select(c("Lemma", "frequency"))
colnames(frequency) <- c("Lemma", "17th")
frequency <- merge(x = frequency, y = select(`18th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
frequency <- merge(x = frequency, y = select(`19th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
frequency <- merge(x = frequency, y = select(`20th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)

colnames(frequency) <- c("Lemma", "17th", "18th", "19th", "20th")

frequency <- melt(data = frequency, id.vars = "Lemma", measure.vars = c("17th", "18th", "19th"))
frequency <- merge(x = frequency, y = select(`20th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
colnames(frequency) <- c("Lemma", "century", "proportion", "20th")

ggplot(frequency, aes(x = proportion, y = `20th`, color = abs(`20th` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = Lemma), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~century, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "20th century", x = NULL) + 
  theme_bw() +
  theme(legend.position = "none")

```

### Total Number of Words vs Count of Unique Words for each Century

```{r echo = FALSE}
num_of_occ <- c(sum(`17th_data`$Number.of.occurences), sum(`18th_data`$Number.of.occurences), sum(`19th_data`$Number.of.occurences), sum(`20th_data`$Number.of.occurences))

num_of_unique <- c(length(unique(`17th_data`$Lemma)), length(unique(`18th_data`$Lemma)), length(unique(`19th_data`$Lemma)), length(unique(`20th_data`$Lemma)))

century_basic <- cbind(century_basic, num_of_occ, num_of_unique)

century_basic_long <- melt(century_basic[,c("centuries", "num_of_occ", "num_of_unique")], id=c("centuries"))

ggplot(century_basic_long) + geom_bar(aes(x = centuries, y = value, fill = variable), stat = "identity", position = "dodge", width = 0.7) + 
  scale_fill_manual("Variable\n", values = c("orange", "blue"), labels = c("Count of All Words", "Count of Unique Words")) + 
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE, big.mark = " ")) +
  labs(x = "\nCenturies", y = "\nNumber of") + 
  theme_bw(base_size = 14)


```

### Count of Unique Words to All Words

```{r echo = FALSE}
century_basic <- century_basic %>% mutate(Unique_to_all = round(num_of_unique/num_of_occ,4))

ggplot(century_basic) + geom_bar(aes(x = centuries, y = Unique_to_all), stat = "identity", width = 0.7, fill ="orange") + 
  scale_y_continuous(labels = function(x) percent(x)) +
  labs(x = "\nCenturies", y = "\nProportion") + 
  theme_bw(base_size = 14)
```

% KK: Zastanawiam się, co w ogóle oznacza ten stosunek i jakie wnioski można wyciągnąć z tego wykresu (z tego co kojarzę, to Ćwiakowski kładł dość mocny nacisk na to, żeby były jakieś wnioski z tego naszego badania). + do wykresu trzeba będzie dodać na lewej osi skalę w % %

We can see that presented proportion is inversely proportional to the stats we could see at the previous plot. However, when interpreting this phenomenon one has to be careful. That is because the data for 18th and 19th century contains much more words than these for 17th and 20th. But what has to be indicated is that when the number of all words is boundless and depends only on number of text analyzed, number of unique words for specific language is limited.


## Part of speech analysis

Stacked Barplot with Percentage of Parts of Speech for Unique Words

```{r echo = FALSE, out.width="800px", out.height="600px"}
`17th_data`$Part_of_speech <- ifelse(`17th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `17th_data`$Part_of_speech, "Other")
`18th_data`$Part_of_speech <- ifelse(`18th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `18th_data`$Part_of_speech, "Other")
`19th_data`$Part_of_speech <- ifelse(`19th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `19th_data`$Part_of_speech, "Other")
`20th_data`$Part_of_speech <- ifelse(`20th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `20th_data`$Part_of_speech, "Other")

Part_of_speech <- cbind(centuries = c(rep(c("17th"),5), rep(c("18th"),5), rep(c("19th"),5), rep(c("20th"),5)),
  rbind(data.frame(`17th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`17th_data`$Part_of_speech) * 100,2))),
      data.frame(`18th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`18th_data`$Part_of_speech) * 100,2))),
      data.frame(`19th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`19th_data`$Part_of_speech) * 100,2))),
      data.frame(`20th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`20th_data`$Part_of_speech) * 100,2)))))


ggplot(Part_of_speech, aes(x = centuries, y = Percentage, fill = Part_of_speech)) + geom_bar(stat = "identity", position = "stack", width = 0.7) + 
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  geom_text(aes(label = paste0(Percentage,"%")), 
            position = position_stack(vjust = 0.5), size = 3) +
  labs(fill = "Part of Speech") +
  ggtitle("Parts of Speech Proportions") + 
  labs(x = "\nCenturies", y = "\nPercentage") + 
  theme_bw(base_size = 14)   
```

## Sentiment analysis

### Sentiment Type to Sum of All Words

```{r echo = FALSE, message = FALSE}
senti_data <- rbind(
                    data.frame(Centuries = "17th", 
                             neg = sum(`17th_data`$neg)/length(`17th_data`$neg), 
                             neu = sum(`17th_data`$neu)/length(`17th_data`$neu),
                             pos = sum(`17th_data`$pos)/length(`17th_data`$pos)),
                    data.frame(Centuries = "18th", 
                             neg = sum(`18th_data`$neg)/length(`18th_data`$neg), 
                             neu = sum(`18th_data`$neu)/length(`18th_data`$neu),
                             pos = sum(`18th_data`$pos)/length(`18th_data`$pos)),
                    data.frame(Centuries = "19th", 
                             neg = sum(`19th_data`$neg)/length(`19th_data`$neg), 
                             neu = sum(`19th_data`$neu)/length(`19th_data`$neu),
                             pos = sum(`19th_data`$pos)/length(`19th_data`$pos)),
                    data.frame(Centuries = "20th", 
                             neg = sum(`20th_data`$neg)/length(`20th_data`$neg), 
                             neu = sum(`20th_data`$neu)/length(`20th_data`$neu),
                             pos = sum(`20th_data`$pos)/length(`20th_data`$pos))
                    )

melt(senti_data) %>% ggplot(aes(x = Centuries, y = value, fill = variable)) + geom_bar(stat = "identity", position = "stack", width = 0.7) + 
  scale_y_continuous(labels = function(x) paste0(x * 100, "%")) +
  geom_text(aes(label = paste0(round(value * 100,2),"%")), 
           position = position_stack(vjust = 0.5), size = 3) + 
  labs(fill = "Sentiment", y = "Percentage") +
  theme_bw(base_size = 14)
```

### Most common positive and negative words
```{r, include=FALSE}
to_plot <- `20th_data` %>% 
  melt(id.vars = c("Lemma", "Number.of.occurences"), measure.vars = c("neg", "pos")) %>% 
  filter(value>0)
to_plot$value <- NULL
colnames(to_plot) <- c("word", "n", "sentiment")
to_plot <- to_plot[,c(1,3,2)]

labels <- c(pos = "positive", neg = "negative")

p1 <- to_plot %>%
  dplyr::group_by(sentiment) %>%
  dplyr::top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y", labeller = labeller(sentiment=labels)) +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip() +
  ggtitle("20th century")  + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()) +
  theme_bw()

to_plot <- `17th_data` %>% 
  melt(id.vars = c("Lemma", "Number.of.occurences"), measure.vars = c("neg", "pos")) %>% 
  filter(value>0)
to_plot$value <- NULL
colnames(to_plot) <- c("word", "n", "sentiment")
to_plot <- to_plot[,c(1,3,2)]

p2 <- to_plot %>%
  dplyr::group_by(sentiment) %>%
  dplyr::top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y", labeller = labeller(sentiment=labels)) +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip() +
  ggtitle("17th century")  + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()) +
  theme_bw()
```

```{r}
grid.arrange(p2, p1, nrow = 2)
```



## Progressive simplification of English language

<img src="BASIC2.png" style="height: 340px"/>

```{r}

`17th_data`$basic <- ifelse(`17th_data`$Lemma %in% basic_words, TRUE, FALSE)
`18th_data`$basic <- ifelse(`18th_data`$Lemma %in% basic_words, TRUE, FALSE)
`19th_data`$basic <- ifelse(`19th_data`$Lemma %in% basic_words, TRUE, FALSE)
`20th_data`$basic <- ifelse(`20th_data`$Lemma %in% basic_words, TRUE, FALSE)

# # Patrze tak testowo, ktore wyrazy NIGDY nie byly uzyte, a sa basic
# basic_words[!(basic_words %in% `17th_data`$Lemma) & 
#               !(basic_words %in% `18th_data`$Lemma) & 
#               !(basic_words %in% `19th_data`$Lemma) & 
#               !(basic_words %in% `20th_data`$Lemma)]
# 
# basic_words[!(basic_words %in% `17th_data`$Lemma)]
# basic_words[!(basic_words %in% `18th_data`$Lemma)]
# basic_words[!(basic_words %in% `19th_data`$Lemma)]
# basic_words[!(basic_words %in% `20th_data`$Lemma)]

num_of_basic_unique <- c(sum(`17th_data`$basic), sum(`18th_data`$basic), sum(`19th_data`$basic), sum(`20th_data`$basic))
century_basic$num_of_basic_unique <- num_of_basic_unique 
num_of_sophisticated_unique <- c(sum(!`17th_data`$basic), sum(!`18th_data`$basic), sum(!`19th_data`$basic), sum(!`20th_data`$basic))
century_basic$num_of_sophisticated_unique <- num_of_sophisticated_unique

num_of_basic_all <- c(sum(`17th_data`$basic * `17th_data`$Number.of.occurences), sum(`18th_data`$basic * `18th_data`$Number.of.occurences),
                      sum(`19th_data`$basic * `19th_data`$Number.of.occurences), sum(`20th_data`$basic * `20th_data`$Number.of.occurences))
num_of_sophisticated_all <- c(sum(ifelse(`17th_data`$basic==TRUE,0,1) * `17th_data`$Number.of.occurences), 
                              sum(ifelse(`18th_data`$basic==TRUE,0,1) * `18th_data`$Number.of.occurences), 
                              sum(ifelse(`19th_data`$basic==TRUE,0,1) * `19th_data`$Number.of.occurences), 
                              sum(ifelse(`20th_data`$basic==TRUE,0,1) * `20th_data`$Number.of.occurences))

century_basic$num_of_basic_all <- num_of_basic_all 
century_basic$num_of_sophisticated_all <- num_of_sophisticated_all 


century_basic_long <- melt(century_basic, id=c("centuries"))

basic_all_words <- century_basic_long %>% 
  filter(variable %in% c("num_of_sophisticated_all", "num_of_basic_all")) %>% 
  group_by(centuries) %>% 
  mutate(relative=value/sum(value))


ggplot(data=basic_all_words, aes(x=centuries, y=value, fill=variable)) +
  geom_bar(stat="identity", position = "fill", width=0.7) +
  ggtitle('Percentage of basic words in all words in literature throughout ages') +
  scale_fill_manual("", values = c("orange", "blue"), labels = c("All basic words", "All sophisticated words")) +
  geom_text(aes(x = centuries, label = percent(relative)), colour = 'white', position="fill", fontface = "bold", vjust=1.5) +
  scale_y_continuous(labels = function(x) percent(x))+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank())

```

### Use of basic words in literature - analysis of unique words

```{r}
basic_unique_words <- century_basic_long %>% 
  filter(variable %in% c("num_of_sophisticated_unique", "num_of_basic_unique")) %>% 
  group_by(centuries) %>% 
  mutate(relative=value/sum(value) * 100) %>% 
  mutate(ypos=cumsum(relative)-relative)

# Basic piechart

ggplot(basic_unique_words, aes(x="", y=value, fill=variable)) +
  geom_bar(stat="identity", width=1, color="white", position = position_fill()) +
  ggtitle('Percentage of unique basic words in unique words \nin literature throughout centuries')+
  coord_polar("y") +
  geom_text(aes(label = percent(relative/100)), color = "white", size=6, position = position_fill(vjust = 0.5)) +
  scale_fill_brewer("",palette="Set1", labels=c("Unique basic words", "Unique sophisticated words")) +
  facet_wrap(facets=. ~ centuries) +
  #scale_fill_manual("", values = c("orange", "blue"), labels = c("Number of Titles", "Number of Authors")) +
  theme_void() + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank())

```

We can see that 



## Additional analysis

Finally, we tried to get to know a little more about authors of the books that we included in our analysis.

### Number of Authors vs Number of Titles

```{r echo = FALSE, out.width="800px", out.height="600px"}
centuries <- c("17th", "18th", "19th", "20th")
number_of_titles <- c(15, 15, 15, 14)

century_basic <- data.frame(centuries, number_of_titles)
century_basic <- cbind(century_basic, authors_data %>% group_by(Century) %>% tally(name = "Number of Authors") %>% select_at("Number of Authors"))
century_basic_long <- melt(century_basic, id=c("centuries"))

ggplot(century_basic_long) + geom_bar(aes(x = centuries, y = value, fill = variable), stat = "identity", position = "dodge", width = 0.7) + 
  scale_fill_manual("Variable\n", values = c("orange", "blue"), labels = c("Number of Titles", "Number of Authors")) + 
  labs(x = "\nCenturies", y = "\nNumber of") + 
  theme_bw(base_size = 14) 
  
```

We can clearly see that in 17th century there was a small number of authors that wrote the most popular books, while later number of authors was almost equal to the number of books.

### Birthplaces of authors

```{r echo=FALSE, out.width="800px", warning=FALSE}
Sys.setenv('MAPBOX_TOKEN' = 'pk.eyJ1IjoiY2ltY2lyaW1jaSIsImEiOiJjazU5ejkwZmQxMjdjM2VxeGdqOGVnMnRkIn0.ZcC-1pGUFVd80U1G0G2yoQ')

map_plot <- authors_data %>% 
  plot_mapbox(lon = ~longitude,
              lat = ~latitude,
              split = ~Century,
              size=2,
              mode = 'scattermapbox+markers',
              text=~paste(Author, Birthplace, sep = "\n"),
              hoverinfo='text',
              marker=list(opacity=0.67, size=15)) %>% 
  layout(title = "Birthplace of the most popular authors from 17th to 20th century",
         mapbox = list(),
         legend = list(orientation='h', y=0.12),
         margin = list(l = 25, r = 25,
                       b = 25, t = 25,
                       pad = 2)
         )

map_plot

```


