---
title: "Evolution of language in literature throughout ages"
author: "Grzegorz Krochmal & Katarzyna Kry≈Ñska"
date: "02.02.2020"
output:
    rmdformats::readthedown:
    keywords: 
    highlight: tango
    code_folding: hide
    df_print: paged
    number_sections: true
    toc_depth: 5
    toc_float:
      collapsed: true
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=FALSE)
library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
library(maps)
library(scales)
library(reshape)
library(wordcloud2)
library(gbm)

# Do usuniecia stopwords z baz
library(tm)

clean_dataset <- function(dataset){
  dataset <-  filter(dataset, !Lemma %in% stopwords(kind="en"))
  dataset <-  filter(dataset, nchar(Lemma) > 1)
  return(dataset)
}

#setwd("C:/Users/grzeg/Desktop/studia/Data Science/2 rok/semestr 1/Advanced_VisualisationR/projekt/Adv_Vis_R_Project")
'17th_data' <- data.frame(readxl::read_xlsx("17th_joined_file.xlsx")) %>% clean_dataset()
'18th_data' <- data.frame(readxl::read_xlsx("18th_joined_file.xlsx")) %>% clean_dataset()
'19th_data' <- data.frame(readxl::read_xlsx("19th_joined_file.xlsx")) %>% clean_dataset()
'20th_data' <- data.frame(readxl::read_xlsx("20th_joined_file.xlsx")) %>% clean_dataset()

authors_data <- data.frame(readxl::read_xlsx("Author_birthplace_with_geo_data.xlsx"))

basic_words <- readLines("basic_words.txt", warn = FALSE) %>% 
  strsplit(",") %>% unlist() %>% 
  strsplit(" ") %>% unlist() %>% 
  strsplit("/") %>% unlist()
basic_words <- basic_words[nchar(basic_words)>1 & !basic_words %in% stopwords(kind="en")]

centuries <- c("17th", "18th", "19th", "20th")
number_of_titles <- c(15, 15, 15, 14)

century_basic <- data.frame(centuries, number_of_titles)
century_basic <- cbind(century_basic, authors_data %>% group_by(Century) %>% tally(name = "Number of Authors") %>% select_at("Number of Authors"))
century_basic_long <- melt(century_basic, id=c("centuries"))
```

The goal of our project is to compare how English language evolved in four corresponding centuries, from 17th century to 20th century. To achieve this aim we collected books from specific centuries from Project Guttenberg. The books we collected were not necessarily written in English - some of them were written in other languages and then translated into English. We believe that even though these books were not originally written in English, their translations reflect English language at the corresponding age.

The initial idea was to get over at least a dozen of titles for each century based on the list of the most popular books for specific period - www.goodreads.com. However for 20th century we encountered the problem with the availability of titles because of copyrights. That's why books from 20th century are not the most popular ones but only these we could get.

## First look at the datasets - wordclouds

To create wordclouds, we used R library *wordcloud2*. We chose words that occur at least 100 times and plot them into a wordcloud, to give a quick glance on how language evolved throughout the ages.

### 17th century

```{r}
wordFreq <- `17th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```


### 18th century

```{r}
wordFreq <- `18th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

### 19th century

```{r}
wordFreq <- `19th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

### 20th century

```{r}
wordFreq <- `20th_data` %>% select(c("Lemma", "Number.of.occurences"))
colnames(wordFreq) <- c("word", "freq")
wordcloud2(data = wordFreq %>% filter(freq>100))
```

We can see that many of the popular words used in 17th century are also the most popular words in later ages - e.g. 'say', 'go', 'see', 'will'. However, there are some words in 17th century that seem outdated - like 'thou', 'shall' or 'thy'. On the other hand, we can see that some words gained popularity over time - e.g. 'like', which was one of the most popular words in 20th century, was less frequent in use before 20th century.

## Word frequencies

To confirm our conclusions, we plotted word frequencies. We can clearly see that compared to 20th century, in 17th century such words as 'thee', 'knight' and 'christ' were used more commonly - and reversely, in 20th century words 'tea', 'archer', 'mrs', 'miss' were much more common. Interestingly, most popular words in 17th century, such as 'go', 'say' and 'will' were also the most popular ones in 20th century.

Similarly, when we compare 18th and 19th century to 20th century, we can see that some words became less popular (like 'clergy', 'army', 'cristo') and some words gained popularity (e.g. 'archer', 'businessman', 'beaufort') but the most popular stayed the same ('come', 'always', 'return').

```{r}
library(scales)

`17th_data`$frequency <- `17th_data`$Number.of.occurences / sum(`17th_data`$Number.of.occurences)
`18th_data`$frequency <- `18th_data`$Number.of.occurences / sum(`18th_data`$Number.of.occurences)
`19th_data`$frequency <- `19th_data`$Number.of.occurences / sum(`19th_data`$Number.of.occurences)
`20th_data`$frequency <- `20th_data`$Number.of.occurences / sum(`20th_data`$Number.of.occurences)

frequency <- `17th_data` %>% select(c("Lemma", "frequency"))
colnames(frequency) <- c("Lemma", "17th")
frequency <- merge(x = frequency, y = select(`18th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
frequency <- merge(x = frequency, y = select(`19th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
frequency <- merge(x = frequency, y = select(`20th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)

colnames(frequency) <- c("Lemma", "17th", "18th", "19th", "20th")

frequency <- melt(data = frequency, id.vars = "Lemma", measure.vars = c("17th", "18th", "19th"))
frequency <- merge(x = frequency, y = select(`20th_data`, c("Lemma", "frequency")), by = "Lemma", all = TRUE)
colnames(frequency) <- c("Lemma", "century", "proportion", "20th")

ggplot(frequency, aes(x = proportion, y = `20th`, color = abs(`20th` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = Lemma), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~century, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "20th century", x = NULL) + 
  theme_bw() +
  theme(legend.position = "none")

```

### Total Number of Words vs Count of Unique Words for each Century

The eighteenth century is a clear winner in the competition of total number of words. It is also the best in the case of number of unique words. However due to the limited size of our dataset this conclusion cannot be seen as a fully realiable statement. 

```{r echo = FALSE}
num_of_occ <- c(sum(`17th_data`$Number.of.occurences), sum(`18th_data`$Number.of.occurences), sum(`19th_data`$Number.of.occurences), sum(`20th_data`$Number.of.occurences))

num_of_unique <- c(length(unique(`17th_data`$Lemma)), length(unique(`18th_data`$Lemma)), length(unique(`19th_data`$Lemma)), length(unique(`20th_data`$Lemma)))

century_basic <- cbind(century_basic, num_of_occ, num_of_unique)

century_basic_long <- melt(century_basic[,c("centuries", "num_of_occ", "num_of_unique")], id=c("centuries"))

ggplot(century_basic_long) + geom_bar(aes(x = centuries, y = value, fill = variable), stat = "identity", position = "dodge", width = 0.7) + 
  scale_fill_manual("Variable\n", values = c("orange", "blue"), labels = c("Count of All Words", "Count of Unique Words")) + 
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE, big.mark = " ")) +
  labs(x = "\nCenturies", y = "\nNumber of") + 
  theme_bw(base_size = 14)


```

### Count of Unique Words to All Words

In case of the proportion of count of unique words to all words for each century the first thing which has to be said that the plot is highly connected with the previous one. We can see the relation that centuries with the lowest number of count of words are the ones with the highes proportion score in this case. It brings us to interesting and somehow obvious pattern for probably all languages. Which is that the number of unique words in language is limited. Therefore after some point it does not matter if we increase the size of dataset in case of words, the number of unique will remain the same but the proportion will obviously go down. 

```{r echo = FALSE}
century_basic <- century_basic %>% mutate(Unique_to_all = round(num_of_unique/num_of_occ,4))

ggplot(century_basic) + geom_bar(aes(x = centuries, y = Unique_to_all), stat = "identity", width = 0.7, fill ="orange") + 
  scale_y_continuous(labels = function(x) percent(x)) +
  labs(x = "\nCenturies", y = "\nProportion") + 
  theme_bw(base_size = 14)
```


## Parts of Speech Analysis

Part of Speech and the proportion in which they are present in the text might give us a valuable information about its character. This can be explained with example of comparison of speeches with one coming from somebody who is an extrovert and the other person being an introvert. We can expect that extrovert personality uses more adjectives than introvert one. The next example might be the case when someone talks a lot about itself or other people. So in some way we can detect a narcisstic personality looking at significantly high share of nouns. Unfortunately the results of our analysis at the dataset we used do not bring us highly differntiated results. The most interesting conclusion is the fact that 20th century is the best in all the categories besides 'Others'. What it might indicate is that Stanford NLP library we used for this task got the best performance on this part of dataset because of its most modern character.  

```{r echo = FALSE, out.width="800px", out.height="600px"}
`17th_data`$Part_of_speech <- ifelse(`17th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `17th_data`$Part_of_speech, "Other")
`18th_data`$Part_of_speech <- ifelse(`18th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `18th_data`$Part_of_speech, "Other")
`19th_data`$Part_of_speech <- ifelse(`19th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `19th_data`$Part_of_speech, "Other")
`20th_data`$Part_of_speech <- ifelse(`20th_data`$Part_of_speech %in% c("VERB", "ADJ", "ADV", "NOUN"), `20th_data`$Part_of_speech, "Other")

Part_of_speech <- cbind(centuries = c(rep(c("17th"),5), rep(c("18th"),5), rep(c("19th"),5), rep(c("20th"),5)),
  rbind(data.frame(`17th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`17th_data`$Part_of_speech) * 100,2))),
      data.frame(`18th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`18th_data`$Part_of_speech) * 100,2))),
      data.frame(`19th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`19th_data`$Part_of_speech) * 100,2))),
      data.frame(`20th_data` %>% group_by(Part_of_speech) %>% summarise(Percentage = round(n()/length(`20th_data`$Part_of_speech) * 100,2)))))


ggplot(Part_of_speech, aes(x = centuries, y = Percentage, fill = Part_of_speech)) + geom_bar(stat = "identity", position = "stack", width = 0.7) + 
  scale_y_continuous(labels = function(x) format(x, scientific = FALSE)) +
  geom_text(aes(label = paste0(Percentage,"%")), 
            position = position_stack(vjust = 0.5), size = 3) +
  labs(fill = "Part of Speech") +
  ggtitle("Parts of Speech Proportions") + 
  labs(x = "\nCenturies", y = "\nPercentage") + 
  theme_bw(base_size = 14)   
```

## Sentiment analysis

### Sentiment Type to Sum of All Words

The conclusion regarding to this plot is similar to the previous one. Here the 20th century is the winner in positive in negative classes, having the lowest share in case of neutrality. The neutrality in sentiment analysis is the group with the highest chances that something which is not really neutral will be classified as such because of lack of information for the algorithm.  

```{r echo = FALSE, message = FALSE}
senti_data <- rbind(
                    data.frame(Centuries = "17th", 
                             neg = sum(`17th_data`$neg)/length(`17th_data`$neg), 
                             neu = sum(`17th_data`$neu)/length(`17th_data`$neu),
                             pos = sum(`17th_data`$pos)/length(`17th_data`$pos)),
                    data.frame(Centuries = "18th", 
                             neg = sum(`18th_data`$neg)/length(`18th_data`$neg), 
                             neu = sum(`18th_data`$neu)/length(`18th_data`$neu),
                             pos = sum(`18th_data`$pos)/length(`18th_data`$pos)),
                    data.frame(Centuries = "19th", 
                             neg = sum(`19th_data`$neg)/length(`19th_data`$neg), 
                             neu = sum(`19th_data`$neu)/length(`19th_data`$neu),
                             pos = sum(`19th_data`$pos)/length(`19th_data`$pos)),
                    data.frame(Centuries = "20th", 
                             neg = sum(`20th_data`$neg)/length(`20th_data`$neg), 
                             neu = sum(`20th_data`$neu)/length(`20th_data`$neu),
                             pos = sum(`20th_data`$pos)/length(`20th_data`$pos))
                    )

melt(senti_data) %>% ggplot(aes(x = Centuries, y = value, fill = variable)) + geom_bar(stat = "identity", position = "stack", width = 0.7) + 
  scale_y_continuous(labels = function(x) paste0(x * 100, "%")) +
  geom_text(aes(label = paste0(round(value * 100,2),"%")), 
           position = position_stack(vjust = 0.5), size = 3) + 
  labs(fill = "Sentiment", y = "Percentage") +
  theme_bw(base_size = 14)
```

### Most common positive and negative words

We also anaylysed how much each word contributed to each sentiment in 17th and 20th century (we are mostly interested in these particular ages as they are the first and the last one). We noticed that in 17th century some of the most common negative words revolved around death ('death', 'die') but they are not amongs 10 most frequently used words in 20th century. 

In case of positive words, we can see that the words that concerned religion - like 'heaven' or 'god' were popular in 17th century, but not in 20th century.

```{r, include=FALSE}
to_plot <- `20th_data` %>% 
  melt(id.vars = c("Lemma", "Number.of.occurences"), measure.vars = c("neg", "pos")) %>% 
  filter(value>0)
to_plot$value <- NULL
colnames(to_plot) <- c("word", "n", "sentiment")
to_plot <- to_plot[,c(1,3,2)]

labels <- c(pos = "positive", neg = "negative")

p1 <- to_plot %>%
  dplyr::group_by(sentiment) %>%
  dplyr::top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y", labeller = labeller(sentiment=labels)) +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip() +
  ggtitle("20th century")  + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()) +
  theme_bw()

to_plot <- `17th_data` %>% 
  melt(id.vars = c("Lemma", "Number.of.occurences"), measure.vars = c("neg", "pos")) %>% 
  filter(value>0)
to_plot$value <- NULL
colnames(to_plot) <- c("word", "n", "sentiment")
to_plot <- to_plot[,c(1,3,2)]

p2 <- to_plot %>%
  dplyr::group_by(sentiment) %>%
  dplyr::top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y", labeller = labeller(sentiment=labels)) +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip() +
  ggtitle("17th century")  + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()) +
  theme_bw()
```

```{r}
grid.arrange(p2, p1, nrow = 2)
```

## Is there a progressive simplification of English language?

Ogden's Basic English is a simplified language created by Charles K. Ogden in 1930. It is based on a theory that 90% of concepts in English language can be explained by only 850 simple words.

Full list of Ogden's Basic English words can be found here: [http://ogden.basic-english.org/]:http://ogden.basic-english.org/

<img src="BASIC3.png" style="height: 340px"/>

### Use of basic words in literature - analysis of all words

To verify the hypothesis that English has been simplified throughout the ages, we checked how many words used in literature were basic in the terms of Ogden's basic English. There has been an decrease in usage of basic words in 18th century compared to 17th century, but it has increased in 19th and 20th centuries. However, there does not seem to be a strong trend.

```{r}

`17th_data`$basic <- ifelse(`17th_data`$Lemma %in% basic_words, TRUE, FALSE)
`18th_data`$basic <- ifelse(`18th_data`$Lemma %in% basic_words, TRUE, FALSE)
`19th_data`$basic <- ifelse(`19th_data`$Lemma %in% basic_words, TRUE, FALSE)
`20th_data`$basic <- ifelse(`20th_data`$Lemma %in% basic_words, TRUE, FALSE)


num_of_basic_unique <- c(sum(`17th_data`$basic), sum(`18th_data`$basic), sum(`19th_data`$basic), sum(`20th_data`$basic))
century_basic$num_of_basic_unique <- num_of_basic_unique 
num_of_sophisticated_unique <- c(sum(!`17th_data`$basic), sum(!`18th_data`$basic), sum(!`19th_data`$basic), sum(!`20th_data`$basic))
century_basic$num_of_sophisticated_unique <- num_of_sophisticated_unique

num_of_basic_all <- c(sum(`17th_data`$basic * `17th_data`$Number.of.occurences), sum(`18th_data`$basic * `18th_data`$Number.of.occurences),
                      sum(`19th_data`$basic * `19th_data`$Number.of.occurences), sum(`20th_data`$basic * `20th_data`$Number.of.occurences))
num_of_sophisticated_all <- c(sum(ifelse(`17th_data`$basic==TRUE,0,1) * `17th_data`$Number.of.occurences), 
                              sum(ifelse(`18th_data`$basic==TRUE,0,1) * `18th_data`$Number.of.occurences), 
                              sum(ifelse(`19th_data`$basic==TRUE,0,1) * `19th_data`$Number.of.occurences), 
                              sum(ifelse(`20th_data`$basic==TRUE,0,1) * `20th_data`$Number.of.occurences))

century_basic$num_of_basic_all <- num_of_basic_all 
century_basic$num_of_sophisticated_all <- num_of_sophisticated_all 


century_basic_long <- melt(century_basic, id=c("centuries"))

basic_all_words <- century_basic_long %>% 
  filter(variable %in% c("num_of_sophisticated_all", "num_of_basic_all")) %>% 
  group_by(centuries) %>% 
  mutate(relative=value/sum(value))


ggplot(data=basic_all_words, aes(x=centuries, y=value, fill=variable)) +
  geom_bar(stat="identity", position = "fill", width=0.7) +
  ggtitle('Percentage of basic words in all words in literature throughout ages') +
  scale_fill_manual("", values = c("orange", "blue"), labels = c("All basic words", "All sophisticated words")) +
  geom_text(aes(x = centuries, label = percent(relative)), colour = 'white', position="fill", fontface = "bold", vjust=1.5) +
  scale_y_continuous(labels = function(x) percent(x))+
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank())

```

### Use of basic words in literature - analysis of unique words

To make our analysis more thorough, we also checked how many of unique words that were used in literature were basic words. We can see that the biggest percentage of basic words used was during 20th century - however, there is no clear trend and we cannot draw any conclusions about simplification of English language.

```{r}
basic_unique_words <- century_basic_long %>% 
  filter(variable %in% c("num_of_sophisticated_unique", "num_of_basic_unique")) %>% 
  group_by(centuries) %>% 
  mutate(relative=value/sum(value) * 100) %>% 
  mutate(ypos=cumsum(relative)-relative)

# Basic piechart

ggplot(basic_unique_words, aes(x="", y=value, fill=variable)) +
  geom_bar(stat="identity", width=1, color="white", position = position_fill()) +
  ggtitle('Percentage of unique basic words in unique words \nin literature throughout centuries')+
  coord_polar("y") +
  geom_text(aes(label = percent(relative/100)), color = "white", size=6, position = position_fill(vjust = 0.5)) +
  scale_fill_brewer("",palette="Set1", labels=c("Unique basic words", "Unique sophisticated words")) +
  facet_wrap(facets=. ~ centuries) +
  #scale_fill_manual("", values = c("orange", "blue"), labels = c("Number of Titles", "Number of Authors")) +
  theme_void() + 
  theme(plot.title = element_text(hjust = 0.5),
        axis.title.y = element_blank(),
        axis.title.x = element_blank())

```



## Additional analysis

Finally, we tried to get to know a little more about authors of the books that we included in our analysis.

### Number of Authors vs Number of Titles

This plot is not represantative in the case of understanding differences between language throughout centuries. It gives us deeper look inside the structure of dataset we used. The pattern which we can highlight in this case is connected to the method of book selection. We based it on the ranking of best books. So for 17th century we can state that there are only a few authors whose occured to be time prone and are still popular.  

```{r echo = FALSE, out.width="800px", out.height="600px"}
centuries <- c("17th", "18th", "19th", "20th")
number_of_titles <- c(15, 15, 15, 14)

century_basic <- data.frame(centuries, number_of_titles)
century_basic <- cbind(century_basic, authors_data %>% group_by(Century) %>% tally(name = "Number of Authors") %>% select_at("Number of Authors"))
century_basic_long <- melt(century_basic, id=c("centuries"))

ggplot(century_basic_long) + geom_bar(aes(x = centuries, y = value, fill = variable), stat = "identity", position = "dodge", width = 0.7) + 
  scale_fill_manual("Variable\n", values = c("orange", "blue"), labels = c("Number of Titles", "Number of Authors")) + 
  labs(x = "\nCenturies", y = "\nNumber of") + 
  theme_bw(base_size = 14) 
  
```


### Birthplaces of authors

The most striking fact about birthplaces of most popular authors is that during 17th and 18th centuries all the influencial authors were born in "Old Europe" - Spain, France, England or Germany. Since 19th century, the distribution became more diverse and we can also observe growing importance of American writers. 

```{r echo=FALSE, out.width="800px", warning=FALSE}
Sys.setenv('MAPBOX_TOKEN' = 'pk.eyJ1IjoiY2ltY2lyaW1jaSIsImEiOiJjazU5ejkwZmQxMjdjM2VxeGdqOGVnMnRkIn0.ZcC-1pGUFVd80U1G0G2yoQ')

map_plot <- authors_data %>% 
  plot_mapbox(lon = ~longitude,
              lat = ~latitude,
              split = ~Century,
              size=2,
              mode = 'scattermapbox+markers',
              text=~paste(Author, Birthplace, sep = "\n"),
              hoverinfo='text',
              marker=list(opacity=0.67, size=15)) %>% 
  layout(title = "Birthplace of the most popular authors from 17th to 20th century",
         mapbox = list(),
         legend = list(orientation='h', y=0.12),
         margin = list(l = 25, r = 25,
                       b = 25, t = 25,
                       pad = 2)
         )

map_plot

```


