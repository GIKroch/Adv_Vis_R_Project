{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "# Stanford NLP library \n",
    "# https://stanfordnlp.github.io/stanfordnlp/installation_usage.html\n",
    "import stanfordnlp\n",
    "nlp = stanfordnlp.Pipeline(processors='tokenize,mwt,pos,lemma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function which extract only words from joined files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words(text): \n",
    "    return re.findall(r'[a-zA-Z]+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Counter dictionary, it shows summed up number of all words which occur in specific joined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grzeg\\Desktop\\studia\\Data Science\\2 rok\\semestr 1\\Advanced_VisualisationR\\projekt\\Adv_Vis_R_Project\\Joined_files\\17th_joined_file.txt\n",
      "C:\\Users\\grzeg\\Desktop\\studia\\Data Science\\2 rok\\semestr 1\\Advanced_VisualisationR\\projekt\\Adv_Vis_R_Project\\Joined_files\\18th_joined_file.txt\n",
      "C:\\Users\\grzeg\\Desktop\\studia\\Data Science\\2 rok\\semestr 1\\Advanced_VisualisationR\\projekt\\Adv_Vis_R_Project\\Joined_files\\19th_joined_file.txt\n",
      "C:\\Users\\grzeg\\Desktop\\studia\\Data Science\\2 rok\\semestr 1\\Advanced_VisualisationR\\projekt\\Adv_Vis_R_Project\\Joined_files\\20th_joined_file.txt\n"
     ]
    }
   ],
   "source": [
    "base_path = r\"C:\\Users\\grzeg\\Desktop\\studia\\Data Science\\2 rok\\semestr 1\\Advanced_VisualisationR\\projekt\\Adv_Vis_R_Project\\Joined_files\"\n",
    "counter_dict = {}\n",
    "for century in os.listdir(base_path):\n",
    "    century_path = base_path + \"\\{}\".format(century)\n",
    "    counter_dict[century] = pl_books = Counter(words(open(century_path, encoding = 'utf-8').read()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for analysis of century specific files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "century_text = counter_dict[\"17th_joined_file.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating dataframe out of dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for word, number in century_text.items():\n",
    "    data.append((word, number))\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Word\", \"Number of occurences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sorting df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by = \"Number of occurences\", ascending = False)\n",
    "df.reset_index(inplace = True)\n",
    "df.drop(columns = [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting stopwords to simplify analysis. It is unnecessary to perform later actions like POS-tagging or sentiment analysis on stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# ## First you have to download stopwords with the code commented below\n",
    "# # nltk.download(\"stopwords\")\n",
    "# from nltk.corpus import stopwords\n",
    "# stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_stopwords(text, stopwords):\n",
    "#     if text in stopwords:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"Stopwords\"] = df[\"Word\"].apply(lambda text:\n",
    "#                                      find_stopwords(text, stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce lemmatization to restrain number of words for future steps like POS-tagging or Sentiment Analysis. Different variations of the same word do not bring us any interesting information in the area of our study so it is better to cut down unnecessary diversity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f is for progress bar\n",
    "def get_lemma(text, f):\n",
    "    f.value += 1\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            return word.lemma\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dcd533326a41c09d4d6852bc922e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=35192)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = IntProgress(min= 0, max = len(df)) # instantiate the bar\n",
    "display(f)\n",
    "\n",
    "\n",
    "df[\"Lemma\"] = df[\"Word\"].apply(lambda text:\n",
    "                              get_lemma(text, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating lemmatized dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After process of lemmatization we can group our dataframe in a way that in further analysis we will be focused only on lemmatized versions of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Number of occurences</th>\n",
       "      <th>Stopwords</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Word2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>47214</td>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and</td>\n",
       "      <td>35721</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>28815</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>28572</td>\n",
       "      <td>1</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "      <td>16513</td>\n",
       "      <td>1</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>16106</td>\n",
       "      <td>1</td>\n",
       "      <td>i</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>that</td>\n",
       "      <td>15865</td>\n",
       "      <td>1</td>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>15799</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it</td>\n",
       "      <td>11123</td>\n",
       "      <td>1</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>is</td>\n",
       "      <td>10921</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>he</td>\n",
       "      <td>10707</td>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>for</td>\n",
       "      <td>9896</td>\n",
       "      <td>1</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>his</td>\n",
       "      <td>9178</td>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>not</td>\n",
       "      <td>9090</td>\n",
       "      <td>1</td>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>8757</td>\n",
       "      <td>1</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>you</td>\n",
       "      <td>8674</td>\n",
       "      <td>1</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>as</td>\n",
       "      <td>8352</td>\n",
       "      <td>1</td>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>this</td>\n",
       "      <td>7349</td>\n",
       "      <td>1</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>be</td>\n",
       "      <td>7266</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>my</td>\n",
       "      <td>7264</td>\n",
       "      <td>1</td>\n",
       "      <td>my</td>\n",
       "      <td>my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>him</td>\n",
       "      <td>6528</td>\n",
       "      <td>1</td>\n",
       "      <td>he</td>\n",
       "      <td>him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>but</td>\n",
       "      <td>6259</td>\n",
       "      <td>1</td>\n",
       "      <td>but</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>all</td>\n",
       "      <td>5815</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>me</td>\n",
       "      <td>5701</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>they</td>\n",
       "      <td>5632</td>\n",
       "      <td>1</td>\n",
       "      <td>they</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>was</td>\n",
       "      <td>5549</td>\n",
       "      <td>1</td>\n",
       "      <td>be</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>by</td>\n",
       "      <td>5527</td>\n",
       "      <td>1</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>have</td>\n",
       "      <td>5467</td>\n",
       "      <td>1</td>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>so</td>\n",
       "      <td>5365</td>\n",
       "      <td>1</td>\n",
       "      <td>so</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>or</td>\n",
       "      <td>5313</td>\n",
       "      <td>1</td>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35162</th>\n",
       "      <td>bescreened</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bescreen</td>\n",
       "      <td>bescreened</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35163</th>\n",
       "      <td>consecutive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>consecutive</td>\n",
       "      <td>consecutive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35164</th>\n",
       "      <td>abets</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>abet</td>\n",
       "      <td>abets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35165</th>\n",
       "      <td>disinclined</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>disinclined</td>\n",
       "      <td>disinclined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35166</th>\n",
       "      <td>reformabitur</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reformabitur</td>\n",
       "      <td>reformabitur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35167</th>\n",
       "      <td>ratifies</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ratify</td>\n",
       "      <td>ratifies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35168</th>\n",
       "      <td>lecturer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>lecturer</td>\n",
       "      <td>lecturer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35169</th>\n",
       "      <td>scutcheon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>scutcheon</td>\n",
       "      <td>scutcheon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35170</th>\n",
       "      <td>chronological</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>chronological</td>\n",
       "      <td>chronological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35171</th>\n",
       "      <td>_provincial_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_provincial_</td>\n",
       "      <td>provincial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35172</th>\n",
       "      <td>891</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>891</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35173</th>\n",
       "      <td>_page_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_page_</td>\n",
       "      <td>page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35174</th>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>889</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35175</th>\n",
       "      <td>_nunquam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_nunquam</td>\n",
       "      <td>nunquam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35176</th>\n",
       "      <td>ecclesia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ecclesia</td>\n",
       "      <td>ecclesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35177</th>\n",
       "      <td>_apothecary_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_apothecary_</td>\n",
       "      <td>apothecary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35178</th>\n",
       "      <td>_peter_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_peter_</td>\n",
       "      <td>peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35179</th>\n",
       "      <td>parentheses</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>parentheses</td>\n",
       "      <td>parentheses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35180</th>\n",
       "      <td>_gregory_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_gregory_</td>\n",
       "      <td>gregory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35181</th>\n",
       "      <td>_sampson_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_sampson_</td>\n",
       "      <td>sampson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35182</th>\n",
       "      <td>_balthasar_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_balthasar_</td>\n",
       "      <td>balthasar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35183</th>\n",
       "      <td>church_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>church_</td>\n",
       "      <td>church</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35184</th>\n",
       "      <td>892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35185</th>\n",
       "      <td>montague_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>montague_</td>\n",
       "      <td>montague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35186</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>893</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35187</th>\n",
       "      <td>laurence_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>laurence_</td>\n",
       "      <td>laurence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35188</th>\n",
       "      <td>_montague_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_montague_</td>\n",
       "      <td>montague</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35189</th>\n",
       "      <td>_paris_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_paris_</td>\n",
       "      <td>paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35190</th>\n",
       "      <td>_escalus_</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>_escalus_</td>\n",
       "      <td>escalus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35191</th>\n",
       "      <td>wive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wive</td>\n",
       "      <td>wive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Number of occurences  Stopwords          Lemma  \\\n",
       "0                the                 47214          1            the   \n",
       "1                and                 35721          1            and   \n",
       "2                 of                 28815          1             of   \n",
       "3                 to                 28572          1             to   \n",
       "4                 in                 16513          1             in   \n",
       "5                  i                 16106          1              i   \n",
       "6               that                 15865          1           that   \n",
       "7                  a                 15799          1              a   \n",
       "8                 it                 11123          1             it   \n",
       "9                 is                 10921          1             be   \n",
       "10                he                 10707          1             he   \n",
       "11               for                  9896          1            for   \n",
       "12               his                  9178          1             he   \n",
       "13               not                  9090          1            not   \n",
       "14              with                  8757          1           with   \n",
       "15               you                  8674          1            you   \n",
       "16                as                  8352          1             as   \n",
       "17              this                  7349          1           this   \n",
       "18                be                  7266          1             be   \n",
       "19                my                  7264          1             my   \n",
       "20               him                  6528          1             he   \n",
       "21               but                  6259          1            but   \n",
       "22               all                  5815          1            all   \n",
       "23                me                  5701          1              I   \n",
       "24              they                  5632          1           they   \n",
       "25               was                  5549          1             be   \n",
       "26                by                  5527          1             by   \n",
       "27              have                  5467          1           have   \n",
       "28                so                  5365          1             so   \n",
       "29                or                  5313          1             or   \n",
       "...              ...                   ...        ...            ...   \n",
       "35162     bescreened                     1          0       bescreen   \n",
       "35163    consecutive                     1          0    consecutive   \n",
       "35164          abets                     1          0           abet   \n",
       "35165    disinclined                     1          0    disinclined   \n",
       "35166   reformabitur                     1          0   reformabitur   \n",
       "35167       ratifies                     1          0         ratify   \n",
       "35168       lecturer                     1          0       lecturer   \n",
       "35169      scutcheon                     1          0      scutcheon   \n",
       "35170  chronological                     1          0  chronological   \n",
       "35171   _provincial_                     1          0   _provincial_   \n",
       "35172            891                     1          0            891   \n",
       "35173         _page_                     1          0         _page_   \n",
       "35174            889                     1          0            889   \n",
       "35175       _nunquam                     1          0       _nunquam   \n",
       "35176       ecclesia                     1          0       ecclesia   \n",
       "35177   _apothecary_                     1          0   _apothecary_   \n",
       "35178        _peter_                     1          0        _peter_   \n",
       "35179    parentheses                     1          0    parentheses   \n",
       "35180      _gregory_                     1          0      _gregory_   \n",
       "35181      _sampson_                     1          0      _sampson_   \n",
       "35182    _balthasar_                     1          0    _balthasar_   \n",
       "35183        church_                     1          0        church_   \n",
       "35184            892                     1          0            892   \n",
       "35185      montague_                     1          0      montague_   \n",
       "35186            893                     1          0            893   \n",
       "35187      laurence_                     1          0      laurence_   \n",
       "35188     _montague_                     1          0     _montague_   \n",
       "35189        _paris_                     1          0        _paris_   \n",
       "35190      _escalus_                     1          0      _escalus_   \n",
       "35191           wive                     1          0           wive   \n",
       "\n",
       "               Word2  \n",
       "0                the  \n",
       "1                and  \n",
       "2                 of  \n",
       "3                 to  \n",
       "4                 in  \n",
       "5                  i  \n",
       "6               that  \n",
       "7                  a  \n",
       "8                 it  \n",
       "9                 is  \n",
       "10                he  \n",
       "11               for  \n",
       "12               his  \n",
       "13               not  \n",
       "14              with  \n",
       "15               you  \n",
       "16                as  \n",
       "17              this  \n",
       "18                be  \n",
       "19                my  \n",
       "20               him  \n",
       "21               but  \n",
       "22               all  \n",
       "23                me  \n",
       "24              they  \n",
       "25               was  \n",
       "26                by  \n",
       "27              have  \n",
       "28                so  \n",
       "29                or  \n",
       "...              ...  \n",
       "35162     bescreened  \n",
       "35163    consecutive  \n",
       "35164          abets  \n",
       "35165    disinclined  \n",
       "35166   reformabitur  \n",
       "35167       ratifies  \n",
       "35168       lecturer  \n",
       "35169      scutcheon  \n",
       "35170  chronological  \n",
       "35171     provincial  \n",
       "35172           None  \n",
       "35173           page  \n",
       "35174           None  \n",
       "35175        nunquam  \n",
       "35176       ecclesia  \n",
       "35177     apothecary  \n",
       "35178          peter  \n",
       "35179    parentheses  \n",
       "35180        gregory  \n",
       "35181        sampson  \n",
       "35182      balthasar  \n",
       "35183         church  \n",
       "35184           None  \n",
       "35185       montague  \n",
       "35186           None  \n",
       "35187       laurence  \n",
       "35188       montague  \n",
       "35189          paris  \n",
       "35190        escalus  \n",
       "35191           wive  \n",
       "\n",
       "[35192 rows x 5 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting parts of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_part_of_speech(text):\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sentences:\n",
    "        for word in sent.words:\n",
    "            return word.upos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
